{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d816c585-499c-46a0-99f0-dd81df192319",
   "metadata": {},
   "source": [
    "## Automated machine learning or AutoML explained\n",
    "- Martin Heller, Infoworld\n",
    "- 2019.08.27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e79911f-94da-4daf-9103-c57a8a115b80",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57112714-c132-4638-bb4d-b1832edeff13",
   "metadata": {},
   "source": [
    "#### `머신러닝(딥러닝 포함)의 장애물`\n",
    "  - 1) 기술력 (데이터 과학자 필요)\n",
    "    - 기술력이 해당 페이지에서 주안점으로 둘 문제임\n",
    "  - 2) 컴퓨팅 자원 (가속 하드웨어 구매, 클라우드의 컴퓨팅 자원 임대 등의 방식으로 해결 가능)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490f2602-b42d-4015-8bb1-9c00f139b5fe",
   "metadata": {},
   "source": [
    "> 컴퓨팅 자원은 장비만 갖추면 되기에 금전적인 부분만 충족된다면 비교적 쉽게 해결 가능\n",
    "\n",
    "> 기술력을 해결할 데이터 과학자를 찾는 것이 쉽지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8654847-4b95-44df-8aa9-a03e6d4e1982",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8b6ce5-20f2-4dbf-afee-f932402422e9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22acb69-4c43-41b2-9b65-27373d9fd1e5",
   "metadata": {},
   "source": [
    "### `AutoML (자동화된 머신러닝) ?`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefd5d9d-c559-4d3e-9b65-d889ae0b9682",
   "metadata": {},
   "source": [
    "- 머신러닝(딥러닝 포함) 구축 시 필요한 데이터 과학자란 조건을 제거할 수 있음\n",
    "- AutoML을 통해 labeling된 학습 데이터를 입력해주면 `최적화된 모델`을 출력해줌\n",
    "  - 이때 학습 데이터를 입력해주면 적절한 예측 결과값으로서 `**모델**`을 출력해주는 것이 중요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd17e2b-1b84-42de-976d-e29776590390",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe83d1ca-7276-43a7-a565-3d426fb250b5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825a3ab6-c045-4f05-9253-e6ab50617381",
   "metadata": {},
   "source": [
    "> ### labeling된 학습 데이터에 따라 최적화 모델을 출력해주는 두가지 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d7e753-d0b8-4224-9acd-0c327267b518",
   "metadata": {},
   "source": [
    "1) 소프트웨어에서 단순히 데이터에 대해 모든 종류의 모델을 학습시킨 다음 가장 결과가 좋은 모델을 선택\n",
    "  \n",
    "  \n",
    "    - 앙상블 모델을 만드는 것 또한 방법이 될 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327e403d-af32-416d-ab81-f27cc87f68a4",
   "metadata": {},
   "source": [
    "2. 최적 모델의 초매개변수를 최적화해서 더 나은 모델로 학습\n",
    "    - HPO(Hyper Parameter Optimizer)\n",
    "    - feature engineering으로 모델 학습\n",
    "    - 혹은 `전이 학습`을 통해 기본적으로 잘 학습되어진 범용 모델을 특정 데이터에 대해 맞춤 구성하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf24fdb-6585-40a5-bef8-d6861c4fb834",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d3a04b-e24c-47b7-b08a-782ba588755e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2f09ed-4809-4424-a8d8-2716acc3c59c",
   "metadata": {},
   "source": [
    "> ### 초매개변수 최적화(Hyper Parameter Optimizer, HPO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8129713-de58-4b4c-9f0e-c31031733f7e",
   "metadata": {},
   "source": [
    "- 대부분의 머신러닝(딥러닝) 모델에는 학습 루프 외부에 설정되는 초매개변수가 있음\n",
    "  - 이를테면, 학습률과 배제율 그리고 트리 수(랜덤 포레스트일 때)와 같은 모델별 매개변수 등이 초매개변수에 해당"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d7ca8f-b655-439a-9b9e-01b146ecc419",
   "metadata": {},
   "source": [
    "- HPO는 하나 이상의 모델 초매개변수를 자동으로 탐색 또는 검색해서 최선의 학습된 모델로 이어지는 집합을 탐색\n",
    "  - ~AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421353f6-f3ef-4578-866b-37f53f10d1ad",
   "metadata": {},
   "source": [
    "- 학습 루프 외부에 설정되는 초매개변수 값들에 대해 모델을 각각 재학습(이땐, 내부 루프) 시켜야 하므로 많은 시간이 소요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52d6df-a00b-4cce-ab99-ed60bd2511ea",
   "metadata": {},
   "source": [
    "$\\to$ 이때 많은 모델을 하드웨어를 늘려 병렬로 학습시키면 필요한 시간을 줄일 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5a8def-67de-47fc-a7cc-27b6d2cd75e1",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199e3fc8-a149-4f16-a92f-9b4ada728320",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f382d7e8-dfa8-4033-81ef-147bd54bca6a",
   "metadata": {},
   "source": [
    "> ### Feature Engineering\n",
    "  - 모든 학습 과정에서의 입력 단계에서 최적의 변수 집합과 최적의 데이터 인코딩 및 정규화를 찾는 과정\n",
    "  - feature enginerrin 시 사용하는 기법 중 하나는 문제를 설명하는 독립 변수의 최소 집합을 선택하는 것\n",
    "    - 두 개의 변수가 고도로 상호 연관됐다면, 둘을 하나의 특성으로 결합하거나 하나는 배제\n",
    "    - PCA를 통해 상호 연관된 변수를 선형적 비상관 변수 집합으로 변환하는 경우도 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ba688d-56ad-4aeb-9c6d-b7447b336fd7",
   "metadata": {},
   "source": [
    "- 또한 머신 러닝 모델 중 분류에 범주 데이터를 사용하려면 텍스트 레이블을 다른 형식으로 인코딩 해야 함\n",
    "  - 1) 레이블 인코딩(텍스트 레이블 값이 숫자로 대체)\n",
    "  - 2) 원-핫 인코딩 (각 텍스트 레이블 값이 이진 값으로 대체)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc108b35-f42e-4170-acea-6a07eec73cb3",
   "metadata": {},
   "source": [
    "- 머신 러닝 모델 중 회귀에 수치 데이터를 사용하려면 일반적으로 데이터를 정규화해야 함\n",
    "  - 최소최대 정규화, 평균 정규화, 표준화, 단위 길이로 스케일링\n",
    "  - 이 프로세스들을 흔히 feature scaling이라 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95806eed-44de-4d38-93af-92565cef0f0a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e662de05-9c56-47eb-bc0d-c9e2289f2c27",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6499272b-879b-4131-9a75-503683116d46",
   "metadata": {},
   "source": [
    "> ### 전이 학습(맞춤 머신러닝)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb25aa9-c8fc-4492-ad02-44dd27a377d8",
   "metadata": {},
   "source": [
    "- 구글 클라우드의 AutoML(구글에서는 전이학습, 즉 맞춤 머신러닝을 AutoML이라고 일컬음)은 데이터로 모델을 처음부터 새로 학습시키는 대신 언어 쌍 번역, 자연어 분류, 이미지 분류를 위해 자동 심층 전이 학습(다른 데이터로 학습된 `기존` 심층 신경망을 사용해 시작)과 신경 architecture 검색(부가적인 네트워크 계층의 적절한 조합을 찾음)을 구현\n",
    "- 일반적인 AutoML의 의미와는 다른 프로세스임\n",
    "  - 다루는 사용 사례도 일반적인 AutoML에 비해 적음\n",
    "  - 반면 지원되는 영역에서 맞춤화된 딥러닝 모델이 필요한 경우 전이 학습이 더 우수한 모델을 생산하기도 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d6e0cb-32de-4b87-b099-eac900d08c0a",
   "metadata": {},
   "source": [
    "> 전이학습 부가설명\n",
    "\n",
    "    딥러닝의 학습 방법 중 하나로서, 분류나 탐지 그리고 분할 업무에 대해 학습된 딥러닝 모델을 다른 데이터셋에 활용하는 것을 말함\n",
    "    \n",
    "    데이터의 수가 적더라도 기존 훈련된 모델에서 얻은 지식을 바탕으로 활용하는 큰 장점이 있다. \n",
    "    \n",
    "    -> 큰 데이터 셋을 사용해서 훈련된 모델을 사전 학습 모델(pre-trained model)이라고 함\n",
    "    -> fine - tuning : 사전 학습 모델의 가중치를 미세하게 조정하는 기법이며, 새롭게 분류하려는 데이터의 종류와 전체 개수를 미리 분석한 후에 그것을 바탕으로 사전 학습 모델 가중치 일부만을 재학습시키거나 또는 모든 가중치를 처음부터 다시 학습시킬 수 있음\n",
    " \n",
    "    \n",
    "    - ### 전이학습의 개괄적 과정 ###\n",
    "    \n",
    "    입력과 출력 데이터에 ~관련이 있는~ 풍부한 예측 모델링 문제를 원본으로 선택\n",
    "    이 문제에 대해 정확도가 높은 원본 모델을 개발(이게 기존 모델의 역할을 할 것임\n",
    "    )하고, 이를 목표 모델에 활용한다. \n",
    "    이러한 모델(기존 모델)을 다듬어서 사용하는 것이 전이학습의 큰 틀이다. \n",
    "    \n",
    "    - ### 전이학습의 활용 예시 ###\n",
    "    \n",
    "    1) 자율주행 일반차량 운전을 위해 훈련된 모델 -> 자율주행 트럭 운전에도 사용\n",
    "    \n",
    "    2) 도로 위의 다른 차량을 감지하는 모델 -> 자율 주행 중 오토바이나 버스를 감지하는 데에 사용\n",
    "    \n",
    "    3) 바둑을 하면서 전략을 발전시킨 모델 -> 체스에도 적용 \n",
    "    \n",
    "    4) 근육의 근전도 신호와 제스처 인식을 위한 뇌파의 유사한 물리적 특성으로 인해 상호간 전이학습이 가능하다.\n",
    "    \n",
    "    5) MRI 스캔 이미지로 훈련된 모델 -> CT 스캔 분석\n",
    "    \n",
    "    6) 이메일 분류를 위해 훈련된 AI 모델 -> 스팸메일 필터링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeb3161-50d0-4592-8b20-dd9f41751c14",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3307f0b-969c-42a8-bd8b-ff328130e2be",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c169d25c-8721-4283-9db3-ac253c69c613",
   "metadata": {},
   "source": [
    "### AutoML 서비스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001ff151-4966-4a28-90da-2da79d82054b",
   "metadata": {},
   "source": [
    "3대 클라우드 서비스에는 모두 일종의 AutoML 서비스가 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475580bc-1bb6-4f35-9329-730a0e3b84ba",
   "metadata": {},
   "source": [
    "1) 아마존 세이지 메이커\n",
    "  - 초매개변수 튜닝을 수행하지만 자동으로 여러 모델을 시도하거나 feature engineering을 수행하지는 않는다. \n",
    "2) 애저 머신러닝\n",
    "  - AutoML(특성과 알고리즘을 탐색)과 초매개변수 튜닝(일반적으로  AutoML에 의해 선택된 최적의 알고리즘을 대상으로 실행)이 있음\n",
    "3) 구글 클라우드 AutoML\n",
    "  - 언어 쌍 번역, 자연어 분류, 이미지 분류를 위한 심층 전이 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae62d83-bdbe-4fda-8d50-82ca03ec717b",
   "metadata": {},
   "source": [
    "그 외 3개 클라우드 외 규모는 작지만 AutoML 서비스 제공 업체\n",
    "- 데이터 로봇\n",
    "- 닷데이터\n",
    "- 에이다넷\n",
    "- 오토케라스\n",
    "- NNI "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d1c0c8-2af6-4f5c-82b7-83b1697d0414",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5eb209-7429-4db7-bd85-c3428b11d671",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf27783-8d15-45ef-a2b9-f3ef67f2be44",
   "metadata": {},
   "source": [
    "> 깃허브에서 확인할 수 있는 다른 AutoML 프로젝트 그리고, AutoML에 대한 포괄적인 논문 목록 링크는 아래 걸어둠"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdde8531-3a5d-4ef8-a3de-e13327e2e8d2",
   "metadata": {},
   "source": [
    "[깃허브의 다른 AutoML 프로젝트와 포괄적인 논문 링크](https://github.com/search?q=automl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98addc2-8b53-4172-b56b-675f024d9d12",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b686cf2-3bbf-42f4-8b2c-d87aeb369f21",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41606f6b-8e4e-4c5f-baf8-89b4495e3c64",
   "metadata": {},
   "source": [
    "### AutoML 부가 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2bdf69-5b14-4687-ae6e-e4629fe45dcf",
   "metadata": {},
   "source": [
    "문제 정의 과정에서부터 데이터 수집, 전처리, 모델 학습 및 평가를 거쳐 서비스 적용에 이르기까지 머신러닝 모델을 개발하고 실제 운영에 도입하기에는 수많은 과정을 거치게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587136d0-3af7-4e53-a6a1-1a51842f9c3e",
   "metadata": {},
   "source": [
    "AutoML은 머신러닝을 적용할 때마다 이러한 과정을 되풀이하면서 발생하는 `비효율적인 작업`을 `최대한 자동화`하여 생산성과 효율을 높이기 위해 등장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9b3c67-5155-44ae-8da9-c1c966dea752",
   "metadata": {},
   "source": [
    "데이터 전처리과정에서부터 알고리즘 선택 및 튜닝까지의 과정에서 모델 개발자의 개입을 최소화하는 것이 목표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b254229-bf4f-4c1f-9791-5dea3fba4d32",
   "metadata": {},
   "source": [
    "### AutoML 기술로 해결하고자 하는 문제 두가지\n",
    "1) 모델을 학습하고 평가할 때 다양한 알고리즘들과 연관된 하이퍼 파라미터들을 실험하고 성능을 비교하여 최상의 성능을 갖는 모델을 찾는 과정을 자동화하는 문제\n",
    "- Combined Algorithm Selection and Hyper-parameter optimization,CASH\n",
    "2) 인공 신경망 기술을 활용함에 있어서 문제에 적합한 architecture를 찾는 과정을 자동화하는 문제\n",
    "- Neural Architecture Search, so called NAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fedd080-92e2-48d7-9674-93c593725963",
   "metadata": {},
   "source": [
    "### CASH ??\n",
    "- 문제에 적합한 알고리즘을 찾고 그 알고리즘의 성능을 극대화 할 수 있는 하이퍼파라미터를 찾는 작업이 수반됨.\n",
    "- 일종의 최적화(Optimizer) 문제로서 CASH라 불림\n",
    "\n",
    "- 1) 전통적인 최적화 알고리즘을 적용하는 방법\n",
    "- 2) 강화학습의 문제로 접근하는 방법\n",
    "- 3) 최적화 과정에서 관찰되는 탐색 결과를 학습하여 다음 탐색 방향을 결정하는 데 이용하는 Bayesian Optimization 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38a235e-96fb-4028-8df8-9971f9cecce2",
   "metadata": {},
   "source": [
    "### NAS ??\n",
    "- Neural-net 기반의 머신 러닝 알고리즘을 사용하기 위해서는 neural architecture를 풀고자 하는 문제에 적합하도록 잘 설계해야 함\n",
    "- NAS는 이 과정을 사람이 직접하지 않고 자동으로 하는 것을 목표로 연구\n",
    "- image classification, object detection, segmentation같은 문제에 대해선 NAS가 기존 사람에 의해 설계된 모델보다 성능이 뛰어날 수 있음이 보고되고 있음\n",
    "  - [해당 논문 링크](https://jmlr.org/papers/volume20/18-598/18-598.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae0da81-dea9-4dcc-9478-caab164c34e5",
   "metadata": {},
   "source": [
    "- NAS 문제를 풀기 위한 방법은 크게 search space를 어떻게 정의하고, 어떤 search 알고리즘을 적용하느냐에 따라 나누어질 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bedd9b-c3bd-41f6-9097-e8db77927ef1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fc30c0-113b-4c00-a232-0b88f53d7b8a",
   "metadata": {},
   "source": [
    "[인공지능을 위한 인공지능, AutoML](https://www.samsungsds.com/kr/insights/ai_automl.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dfc01f-e7f7-451f-b2d6-b9822172e648",
   "metadata": {},
   "source": [
    "> 도메인과 애플리케이션별 고품질의 학습데이터 준비, 적합한 feature의 자동생성 그리고 최적의 머신러닝 설계를 무인화하는 학습지능 기술과 고성능 AI 기술과 동시 제공돼야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c92ee8-56ae-47d3-9f20-31883ac23925",
   "metadata": {},
   "source": [
    "> 많은 AI 모델 개발 과정에서의 비효율성을 조금씩 개선하는 관점"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c57e4f7-fc63-4a13-9671-579c4175299c",
   "metadata": {},
   "source": [
    "> 사람의 반복적인 시행착오에 의한 머신러닝 초매개변수를 자동 미세 조정하는 수준일 뿐임. 궁극적인 머신러닝 파이프라인 전체를 해결해야 한다는 목표는 아득히 먼 수준임"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
